# Vision Transformer (ViT) - From Scratch

## üîç Overview

This project provides an implementation of the research paper "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale". Using Pytorch, features like patch embeddings, multi-head self attention, encoders, and the ViT are implemented from scratch. This project then trains the ViT on CIFAR-10 and records 11 trials. The model performs with 85.7% accuracy on the final test set.  

## üõ†Ô∏è Dependency installation
Clone the repo:

```bash
git clone https://github.com/vjhawar12/Vision-Transformer-paper-implementation.git
cd Vision-Transformer-paper-implementation
```

Install the dependencies:

```bash
pip install -r requirements.txt
```

## üöÄ Running the Notebook

1. Open the notebook:

```bash
jupyter notebook Vision_Transformer_from_scratch.ipynb
```

Or use Google Colab.

2. Run all cells sequentially.
