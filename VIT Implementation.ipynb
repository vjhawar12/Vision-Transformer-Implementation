{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install lightning-bolts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZvA46AlIhO1",
        "outputId": "c3620d95-771b-4063-b996-37205044eaf9"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lightning-bolts in /usr/local/lib/python3.11/dist-packages (0.7.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from lightning-bolts) (2.0.2)\n",
            "Requirement already satisfied: pytorch-lightning<2.0.0,>1.7.0 in /usr/local/lib/python3.11/dist-packages (from lightning-bolts) (1.9.5)\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.11/dist-packages (from lightning-bolts) (1.7.4)\n",
            "Requirement already satisfied: lightning-utilities>0.3.1 in /usr/local/lib/python3.11/dist-packages (from lightning-bolts) (0.14.3)\n",
            "Requirement already satisfied: torchvision>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from lightning-bolts) (0.21.0+cu124)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.11/dist-packages (from lightning-bolts) (2.18.0)\n",
            "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>0.3.1->lightning-bolts) (24.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>0.3.1->lightning-bolts) (75.2.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>0.3.1->lightning-bolts) (4.14.0)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (6.0.2)\n",
            "Requirement already satisfied: fsspec>2021.06.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (2025.3.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->lightning-bolts) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->lightning-bolts) (1.73.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->lightning-bolts) (3.8.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->lightning-bolts) (5.29.5)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->lightning-bolts) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->lightning-bolts) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->lightning-bolts) (3.1.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision>=0.10.0->lightning-bolts) (11.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.10.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (1.3.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (3.11.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->lightning-bolts) (3.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (1.20.1)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (3.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9eTx9bDPC4S",
        "outputId": "a8468e5f-1e42-4d86-dd45-f7f46dd9c203"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (1.0.16)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from timm) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm) (0.21.0+cu124)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm) (0.33.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (1.1.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->timm) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->timm) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->timm) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->timm) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2025.6.15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "Ib_-nKcWpubJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "from math import sqrt\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pl_bolts.optimizers.lr_scheduler import LinearWarmupCosineAnnealingLR\n",
        "from torchvision.transforms.v2 import CutMix, MixUp, RandomChoice, RandAugment\n",
        "from timm.loss import SoftTargetCrossEntropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "jsVKhKRFB-uc"
      },
      "outputs": [],
      "source": [
        "\n",
        "# image pre-processing helper class\n",
        "\n",
        "class PatchEmbedding(nn.Module):\n",
        "\n",
        "    def __init__(self, batches=32, in_channels=3, patch_size=16, size=128, embed_dim=768):\n",
        "        super().__init__()\n",
        "\n",
        "        assert size % patch_size == 0, \"Image size must be divisible by patch size\"\n",
        "\n",
        "        self.batches = batches\n",
        "        self.in_channels = in_channels # rgb ==> 3 channels\n",
        "        self.patch_size = patch_size # size of each patch (like a token)\n",
        "        self.embed_dim = embed_dim # the higher-dimensional space to project the patches to\n",
        "        self.size = size # size of input image\n",
        "        self.N = (self.size // self.patch_size) ** 2 # number of patches\n",
        "\n",
        "        self.proj = nn.Conv2d(in_channels=self.in_channels, # B, C, H, W --> B, D, H_p, W_p\n",
        "                              out_channels=self.embed_dim, # 3D space --> 768D space to extract more information\n",
        "                              kernel_size=self.patch_size, # so that the patches don't overlap\n",
        "                              stride=self.patch_size) # divides input image into patches\n",
        "\n",
        "        self.cls_token = nn.Parameter(torch.randn(1, 1, self.embed_dim)) # token which captures the 'meaning' of the image in a vector\n",
        "        self.pos_embeddings = nn.Parameter(torch.randn(1, self.N + 1, self.embed_dim)) # the positional embeddings which will be added later\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.proj(x) # applying conv2d projection\n",
        "        x = torch.flatten(x, 2) # B, D, N\n",
        "        x = x.transpose(1, 2) # B, N, D\n",
        "        B = x.shape[0]\n",
        "        cls_token = self.cls_token.expand(B, -1, -1) # expanding the cls token along the batch dimension so it can be added later\n",
        "        x = torch.cat((cls_token, x), dim=1) # adding the cls token to the input tensor\n",
        "        x = x + self.pos_embeddings # now each vector is aware of the position of the word\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "dIAuFEHgB8ka"
      },
      "outputs": [],
      "source": [
        "\n",
        "class ManualMultiHeadSelfAttention(nn.Module):\n",
        "    def __init__(self, embed_dim=768, heads=12):\n",
        "        super().__init__()\n",
        "\n",
        "        assert embed_dim % heads == 0, \"Embedding dimension must be divisible by heads\"\n",
        "\n",
        "        self.embed_dim = embed_dim\n",
        "        self.heads = heads\n",
        "        self.head_dim = embed_dim // heads\n",
        "\n",
        "        # fully connected NN layers with # of input neurons = embed_dim = # output neurons\n",
        "        self.Q_proj = nn.Linear(embed_dim, embed_dim)\n",
        "        self.V_proj = nn.Linear(embed_dim, embed_dim)\n",
        "        self.K_proj = nn.Linear(embed_dim, embed_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.15)\n",
        "\n",
        "        self.output = nn.Linear(embed_dim, embed_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, N, D = x.shape\n",
        "\n",
        "        # sending the input tensor through proj NN layers\n",
        "        Q = self.Q_proj(x) # batches, patches, embed_dim\n",
        "        Q = Q.view(B, N, self.heads, self.head_dim).permute(0, 2, 1, 3) # single head --> multihead\n",
        "\n",
        "        V = self.V_proj(x) # batches, patches, embed_dim\n",
        "        V = V.view(B, N, self.heads, self.head_dim).permute(0, 2, 1, 3) # single head --> multihead\n",
        "\n",
        "        K = self.K_proj(x) # batches, patches, embed_dim\n",
        "        K = K.view(B, N, self.heads, self.head_dim).permute(0, 2, 1, 3) # single head --> multihead\n",
        "\n",
        "        # computing attention\n",
        "        x = self.compute_attention(Q, K, V).permute(0, 2, 1, 3).contiguous() # B, heads, N, head_dim --> B, N, heads, head_dim\n",
        "        x = self.dropout(x)\n",
        "        x = x.view(B, N, D)\n",
        "        x = self.output(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def compute_attention(self, Q, K, V):\n",
        "        K_T = torch.transpose(K, -2, -1) # transpose so that multiplication is defined\n",
        "        scaling = sqrt(self.head_dim)\n",
        "        val = torch.matmul(Q, K_T) / scaling\n",
        "\n",
        "        return torch.matmul(torch.softmax(val, dim=-1), V)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "U1mBFPKCB63T"
      },
      "outputs": [],
      "source": [
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(self, embed_dim=768, heads=12):\n",
        "        super().__init__()\n",
        "\n",
        "        self.mhsa = ManualMultiHeadSelfAttention(embed_dim, heads)\n",
        "        self.ln1 = nn.LayerNorm(embed_dim)\n",
        "\n",
        "        self.ffn = nn.Sequential(\n",
        "            nn.Linear(embed_dim, embed_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.05),\n",
        "            nn.Linear(embed_dim, embed_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.05),\n",
        "        )\n",
        "\n",
        "        self.ln2 = nn.LayerNorm(embed_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.ln1(x) # normalizing activation functions to prevent saturation. Pre-norm is expected to lead to faster convergence.\n",
        "        attn_out = self.mhsa(x) # computing residual\n",
        "        x = x + attn_out # skip connection\n",
        "        x = self.ln2(x) # normalizing activation functions to prevent saturation\n",
        "        ffn_out = self.ffn(x) # computing residual\n",
        "        x = x + ffn_out # skip connection\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "yImRUHuKB3y8"
      },
      "outputs": [],
      "source": [
        "class VisionTransformer(nn.Module):\n",
        "    def __init__(self,  batches=32, in_channels=3, patch_size=16, size=128, embed_dim=768, heads=12, depth=8, num_classes=10):\n",
        "        super().__init__()\n",
        "\n",
        "        self.patch_embedding = PatchEmbedding(batches, in_channels, patch_size, size, embed_dim)\n",
        "        self.transformer_stack = nn.ModuleList(TransformerEncoder(embed_dim, heads) for _ in range(depth))\n",
        "\n",
        "        self.mlp_head = nn.Sequential(\n",
        "            nn.Dropout(0.05),\n",
        "            nn.Linear(in_features=embed_dim, out_features=num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.patch_embedding(x)\n",
        "\n",
        "        for t in self.transformer_stack:\n",
        "            x = t(x)\n",
        "\n",
        "        cls = x[:, 0]\n",
        "        x = self.mlp_head(cls)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "q7KmwLxCByjQ"
      },
      "outputs": [],
      "source": [
        "train_transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.RandomHorizontalFlip(),\n",
        "    torchvision.transforms.RandomCrop(32, padding=4),\n",
        "    torchvision.transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    RandAugment(num_ops=1, magnitude=5),\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize((0.49139968, 0.48215827, 0.44653124), (0.24703233, 0.24348505, 0.26158768)) # normalizing mean helps optims like Adam, scaling ensures uniformity across the inputs\n",
        "])\n",
        "\n",
        "test_transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize((0.49139968, 0.48215827, 0.44653124), (0.24703233, 0.24348505, 0.26158768))\n",
        "])\n",
        "\n",
        "\n",
        "training_data = datasets.CIFAR10(root=\"data\", train=True, download=True, transform=train_transform)\n",
        "test_data = datasets.CIFAR10(root=\"data\", train=False, download=False,  transform=test_transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "OchZkcJJBvvT"
      },
      "outputs": [],
      "source": [
        "batchsize = 256\n",
        "channels = 3\n",
        "patchsize = 4\n",
        "imsize = 32\n",
        "embeddim = 192\n",
        "numheads = 12\n",
        "encoders = 9\n",
        "numclasses = 10\n",
        "epochs = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mje1v_iSBr5N",
        "outputId": "8c8469a3-72f8-40df-fec3-91f32d9f0e4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-80-2603508192.py:20: UnderReviewWarning: The feature LinearWarmupCosineAnnealingLR is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  scheduler = LinearWarmupCosineAnnealingLR(optim, warmup_epochs=5, max_epochs=epochs, eta_min=1e-6, warmup_start_lr=1e-6)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VisionTransformer(\n",
              "  (patch_embedding): PatchEmbedding(\n",
              "    (proj): Conv2d(3, 192, kernel_size=(4, 4), stride=(4, 4))\n",
              "  )\n",
              "  (transformer_stack): ModuleList(\n",
              "    (0-8): 9 x TransformerEncoder(\n",
              "      (mhsa): ManualMultiHeadSelfAttention(\n",
              "        (Q_proj): Linear(in_features=192, out_features=192, bias=True)\n",
              "        (V_proj): Linear(in_features=192, out_features=192, bias=True)\n",
              "        (K_proj): Linear(in_features=192, out_features=192, bias=True)\n",
              "        (dropout): Dropout(p=0.15, inplace=False)\n",
              "        (output): Linear(in_features=192, out_features=192, bias=True)\n",
              "      )\n",
              "      (ln1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "      (ffn): Sequential(\n",
              "        (0): Linear(in_features=192, out_features=192, bias=True)\n",
              "        (1): GELU(approximate='none')\n",
              "        (2): Dropout(p=0.05, inplace=False)\n",
              "        (3): Linear(in_features=192, out_features=192, bias=True)\n",
              "        (4): GELU(approximate='none')\n",
              "        (5): Dropout(p=0.05, inplace=False)\n",
              "      )\n",
              "      (ln2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (mlp_head): Sequential(\n",
              "    (0): Dropout(p=0.05, inplace=False)\n",
              "    (1): Linear(in_features=192, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "train_dataloader = DataLoader(dataset=training_data, batch_size=batchsize, shuffle=True, pin_memory=True)\n",
        "test_dataloader = DataLoader(dataset=test_data, batch_size=batchsize, shuffle=False)\n",
        "\n",
        "cutmix = CutMix(num_classes=numclasses)\n",
        "mixup = MixUp(num_classes=numclasses)\n",
        "\n",
        "vit = VisionTransformer(\n",
        "    batches=batchsize, in_channels=channels,\n",
        "    patch_size=patchsize, embed_dim=embeddim,\n",
        "    heads=numheads, depth=encoders, size=imsize,\n",
        "    num_classes=numclasses\n",
        ")\n",
        "\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "sft_loss_fn = SoftTargetCrossEntropy()\n",
        "optim = torch.optim.AdamW(params=vit.parameters(), lr=0.002, weight_decay=0.05)\n",
        "scheduler = LinearWarmupCosineAnnealingLR(optim, warmup_epochs=5, max_epochs=epochs, eta_min=1e-6, warmup_start_lr=1e-6)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "vit.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = torch.amp.GradScaler()\n",
        "\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True"
      ],
      "metadata": {
        "id": "TSTrhW3Je-k9"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "tWF2eUuhBmS3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "outputId": "8693c382-020f-44fc-c14c-45ccee6cf617"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100: 100%|██████████| 196/196 [01:02<00:00,  3.15it/s, loss=2.38]\n",
            "/tmp/ipython-input-82-690563021.py:45: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: \t Accuracy: 0.09456 \t Val accuracy: 0.1123\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/100:  24%|██▍       | 47/196 [00:15<00:47,  3.12it/s, loss=2.05]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-82-690563021.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for i in range(epochs):\n",
        "    correct, total = 0, 0\n",
        "    vit.train(True)\n",
        "\n",
        "    loop = tqdm(train_dataloader, desc=f\"Epoch {i+1}/{epochs}\", leave=True)\n",
        "\n",
        "    for input, labels in loop:\n",
        "        input, labels = input.to(device), labels.to(device)\n",
        "        optim.zero_grad()\n",
        "\n",
        "        if i + 1 >= 25 and torch.rand(1).item() < 0.5:\n",
        "            cutmix_or_mixup = RandomChoice([cutmix, mixup], p=[0.7, 0.3])\n",
        "            input, labels = cutmix_or_mixup(input, labels)\n",
        "            output = vit(input)\n",
        "            loss = sft_loss_fn(output, labels)\n",
        "        elif i + 1 >= 10 and torch.rand(1).item() < 0.5:\n",
        "            input, labels = mixup(input, labels)\n",
        "            output = vit(input)\n",
        "            loss = sft_loss_fn(output, labels)\n",
        "        else:\n",
        "            output = vit(input)\n",
        "            loss = loss_fn(output, labels)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optim)\n",
        "\n",
        "        scaler.update()\n",
        "\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "        if labels.ndim == 2:\n",
        "          labels = labels.argmax(dim=1)\n",
        "\n",
        "        pred = torch.argmax(output, dim=1)\n",
        "        total += labels.size(0)\n",
        "        correct += (pred == labels).sum().item()\n",
        "\n",
        "    vit.eval()\n",
        "    val_total, val_correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for image, label in test_dataloader:\n",
        "            image, label = image.to(device), label.to(device)\n",
        "\n",
        "            with torch.cuda.amp.autocast():\n",
        "              output = vit(image)\n",
        "\n",
        "            pred = torch.argmax(output, dim=1)\n",
        "            val_total += label.size(0)\n",
        "            val_correct += (pred == label).sum().item()\n",
        "\n",
        "        val_accuracy = val_correct / val_total\n",
        "        accuracy = correct / total\n",
        "\n",
        "\n",
        "    scheduler.step()\n",
        "    print(f\"Epoch {i + 1}: \\t Accuracy: {accuracy} \\t Val accuracy: {val_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_loss_6 = [\n",
        "    762.87,\n",
        "    654.60,\n",
        "    610.51,\n",
        "    580.71,\n",
        "    560.44,\n",
        "    543.26,\n",
        "    526.28,\n",
        "    513.83,\n",
        "    499.53,\n",
        "    442.34,\n",
        "    435.16,\n",
        "    426.84,\n",
        "    419.30,\n",
        "    413.18,\n",
        "    407.64,\n",
        "    398.95,\n",
        "    392.66,\n",
        "    385.60\n",
        "]\n",
        "\n",
        "training_loss_7 = [\n",
        "    751.32,\n",
        "    643.59,\n",
        "    599.94,\n",
        "    571.05,\n",
        "    552.35,\n",
        "    501.65,\n",
        "    488.99,\n",
        "    477.56,\n",
        "    466.41,\n",
        "    456.77,\n",
        "    447.05,\n",
        "    419.97,\n",
        "    412.00,\n",
        "    397.69,\n",
        "    383.77,\n",
        "    368.06,\n",
        "    351.56,\n",
        "    336.02\n",
        "]\n",
        "\n",
        "plt.plot(training_loss_6, label=\"Trial 6\", color='r')\n",
        "plt.plot(training_loss_7, label=\"Trial 7\", color='b')\n",
        "\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Per-epoch training Loss\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "egg1IKtHiADi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SdddyiTcrdY2"
      },
      "outputs": [],
      "source": [
        "vit.eval()\n",
        "total, correct = 0, 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for image, label in test_dataloader:\n",
        "        image, label = image.to(device), label.to(device)\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "          output = vit(image)\n",
        "\n",
        "        pred = torch.argmax(output, dim=1)\n",
        "        total += label.size(0)\n",
        "        correct += (pred == label).sum().item()\n",
        "\n",
        "    accuracy = correct / total\n",
        "\n",
        "    print(f\"Accuracy: {accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SUV1MIa8GqYs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "    'Trial #': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
        "    'Embedding dimension': [384, 384, 384, 192, 192, 192, 256, 192, None, None],\n",
        "    'Number of heads': [12, 12, 12, 12, 12, 8, 8, 12, None, None],\n",
        "    'Number of encoders': [8, 8, 8,  8, 8, 8, 6, 9, None, None],\n",
        "    'Batch size': [128, 128, 128, 128, 128, 128, 128, 128, None, None],\n",
        "    'Epochs': [20, 20, 50,  30, 30, 30, 30, 100, None, None],\n",
        "    'Patch size': [4, 4, 4,  4, 4, 4, 4, 4, None, None],\n",
        "    'Optimizer': ['SGD', 'Adam', 'SGD',  \"AdamW\", \"AdamW\", \"AdamW\", \"AdamW\", \"AdamW\", None, None],\n",
        "    'Learning rate': [0.001, 0.001, 0.1,  3e-4, 3e-4, 3e-4, \"3e-4 with 1e-5 weight decay\", \"0.002 with 0.05 weight decay\", None, None],\n",
        "    'Normalization': ['No', 'No', 'Yes',  'Yes', 'Yes', 'Yes', 'Yes', \"Yes\", None, None],\n",
        "    'Loss function': ['Cross entropy', 'Cross entropy', 'Cross entropy',  'Cross entropy', 'Cross entropy', 'Cross entropy', 'Cross entropy', 'Cross entropy', None, None],\n",
        "    'Dropout regularization value': [None, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.10, None, None],\n",
        "    'Data Augmentation': [None, None, \"Jittering + horizontal flip\", \"Jittering + random crop + horizontal flip\", \"Jittering + random crop + horizontal flip\",  \"Jittering + random crop + horizontal flip\", \"Jittering + random crop + horizontal flip\", \"Jittering + random crop + horizontal flip + RandAugment\" , None, None],\n",
        "    'Scheduler': [None, None, None, \"Cosine Annealing LR\", \"Cosine Annealing LR\", \"Cosine Annealing LR\", \"Cosine Annealing LR\", \"Cosine Annealing LR + linear warmup\", None, None],\n",
        "    'Accuracy %': [23.24, 23.24, 33.36, 10.00, 37.53,  70.49, 71.44, None, None, None],\n",
        "}\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "df"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}